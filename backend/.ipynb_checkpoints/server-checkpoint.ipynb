{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba0dfd-ca9f-4bbc-9616-e568b12a1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import asyncio\n",
    "import spacy\n",
    "import re\n",
    "from spacy.matcher import Matcher\n",
    "from transformers import pipeline , AutoModelForCausalLM, AutoTokenizer\n",
    "from fastapi import FastAPI, File, UploadFile,HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from io import BytesIO\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "import traceback\n",
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Hugging Face token from .env\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "GPT_API=os.getenv(\"GPT_KEY\")\n",
    "\n",
    "openai = OpenAI(api_key=GPT_API)\n",
    "\n",
    "\n",
    "if not HUGGINGFACE_TOKEN:\n",
    "    raise ValueError(\"Hugging Face token not found! Please set HUGGINGFACE_TOKEN in .env\")\n",
    "\n",
    "\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Groq API key not found! Please set GROQ_API_KEY in .env\")\n",
    "\n",
    "# Configure OpenAI client to use Groq\n",
    "client = OpenAI(api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Enable CORS for frontend requests\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Update for production\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Load Spacy NLP Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Transformer Model for Summarization\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_bytes: bytes) -> str:\n",
    "    \"\"\"Extracts raw text from a PDF file using pdfplumber.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_sentences_with_numeric_data(text):\n",
    "    \"\"\"Extracts key financial sentences with numeric data.\"\"\"\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    matcher.add(\"MONEY_PATTERNS\", [\n",
    "        [{\"LIKE_NUM\": True}, {\"TEXT\": {\"IN\": [\"$\", \"₹\", \"€\", \"£\", \"¥\"]}}],\n",
    "        [{\"TEXT\": {\"IN\": [\"$\", \"₹\", \"€\", \"£\", \"¥\"]}}, {\"LIKE_NUM\": True}],\n",
    "        [{\"TEXT\": {\"IN\": [\"$\", \"₹\", \"€\", \"£\", \"¥\"]}}, {\"IS_DIGIT\": True}],\n",
    "        [{\"LIKE_NUM\": True}, {\"LOWER\": {\"IN\": [\"dollars\", \"rupees\", \"euros\", \"pounds\", \"yen\"]}}],\n",
    "        [{\"LIKE_NUM\": True}, {\"LOWER\": \"rs\"}, {\"TEXT\": {\"REGEX\": r\"\\.?\"}}]\n",
    "    ])\n",
    "\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    page_number_pattern = re.compile(r'(\\bpage\\s*\\d+\\b)|(\\bpg\\.\\s*\\d+\\b)|(\\b\\d+\\s*/\\s*\\d+\\b)|(\\bpage\\s*\\d+\\s*of\\s*\\d+\\b)', flags=re.IGNORECASE)\n",
    "    slash_word_pattern = re.compile(r'\\b\\w+/\\w+\\b')\n",
    "    triple_slash_pattern = re.compile(r'\\S*///\\S*')\n",
    "\n",
    "    doc = nlp(text)\n",
    "    sentences_with_numeric_data = set()\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"DATE\", \"TIME\", \"MONEY\", \"PERCENT\"]:\n",
    "            sentences_with_numeric_data.add(ent.sent.start)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        sent_index = doc[start].sent.start\n",
    "        sentences_with_numeric_data.add(sent_index)\n",
    "\n",
    "    number_pattern = re.compile(r'\\b\\d+\\b|\\b\\d+[.,]\\d+\\b')\n",
    "    for sent in doc.sents:\n",
    "        if number_pattern.search(sent.text):\n",
    "            sentences_with_numeric_data.add(sent.start)\n",
    "\n",
    "    result = []\n",
    "    for sent in doc.sents:\n",
    "        if sent.start in sentences_with_numeric_data:\n",
    "            clean_sentence = url_pattern.sub('', sent.text)\n",
    "            clean_sentence = page_number_pattern.sub('', clean_sentence)\n",
    "            clean_sentence = slash_word_pattern.sub('', clean_sentence)\n",
    "            clean_sentence = triple_slash_pattern.sub('', clean_sentence)\n",
    "            clean_sentence = clean_sentence.strip()\n",
    "            if clean_sentence:\n",
    "                result.append(clean_sentence)\n",
    "\n",
    "    return \" \".join(result)\n",
    "\n",
    "def chunk_text(text, tokenizer, max_tokens=512):\n",
    "    \"\"\"Split text into smaller chunks for summarization.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=False)\n",
    "    input_ids = inputs[\"input_ids\"][0]\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(input_ids), max_tokens):\n",
    "        chunk_ids = input_ids[i:i + max_tokens]\n",
    "        chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def summarize_text(text, max_tokens=512):\n",
    "    \"\"\"Summarizes extracted financial data.\"\"\"\n",
    "    tokenizer = summarizer.tokenizer\n",
    "    chunks = chunk_text(text, tokenizer, max_tokens=max_tokens)\n",
    "    summaries = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(chunk, max_length=80, min_length=30, do_sample=False)[0]['summary_text']\n",
    "        summaries.append(summary)\n",
    "\n",
    "    return \" \".join(summaries)\n",
    "\n",
    "#gpt story\n",
    "def chatgpt_generate_story(summary):\n",
    "    \"\"\"Generates a financial story with twists and turns using ChatGPT API.\"\"\"\n",
    "    if not openai.api_key:\n",
    "        print(\"Error: OpenAI API key not found.\")\n",
    "        return \"API Key Missing\"\n",
    "\n",
    "    prompt = (\n",
    "        \"Here is the financial summary you need to convert into a story. Please ensure clarity, engagement, and an easy-to-follow structure while maintaining factual accuracy. Make sure to conclude with a well-reasoned outlook on the company’s future trajectory. \"\n",
    "        f\"Summary: {summary}\\n\\nStory:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "      system_message=\"\"\"You are a skilled financial storyteller with the ability to break down complex financial data into engaging, easy-to-understand narratives. Your goal is to transform a given financial summary into a compelling story that explains key financial events, trends, and figures in a way that anyone—regardless of their financial background—can grasp.\n",
    "\n",
    "Your story should be:\n",
    "\n",
    "Engaging: Use an approachable tone, like a journalist explaining financial news to a general audience.\n",
    "\n",
    "Simple & Clear: Avoid jargon when possible; when using technical terms, explain them in simple words.\n",
    "\n",
    "Well-Structured: Start with an introduction that sets the stage, followed by a breakdown of key figures, trends, and their impact.\n",
    "\n",
    "Relatable: Use analogies and real-world comparisons to make numbers and trends easier to grasp.\n",
    "\n",
    "Forward-Looking: Provide insights into where the company is headed based on financial trends, market conditions, and strategic decisions. Predict potential risks and opportunities in a balanced manner.\n",
    "\"\"\"\n",
    "      user_prompt=prompt\n",
    "      prompts = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ]\n",
    "      completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "      return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API Error: {e}\")\n",
    "        return \"Story generation failed.\"\n",
    "\n",
    "#red_flag_prompt\n",
    "def chatgpt_generate_green(summary):\n",
    "    \"\"\"Generates a financial story with twists and turns using ChatGPT API.\"\"\"\n",
    "    if not openai.api_key:\n",
    "        print(\"Error: OpenAI API key not found.\")\n",
    "        return \"API Key Missing\"\n",
    "\n",
    "    prompt = (\n",
    "        \"Here is the financial summary: \"\n",
    "        f\"Summary: {summary}\\n\\nRed flags: \"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "      system_message=\"\"\"You are a financial analyst tasked with identifying green flags—positive signs that indicate strong financial health, growth potential, or competitive advantages for a company. Your goal is to analyze the given financial summary while also leveraging pre-existing knowledge about the company to highlight strengths and opportunities. Stick to at max 5 points and give it in bullet points\n",
    "\"\"\"\n",
    "      user_prompt=prompt\n",
    "      prompts = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ]\n",
    "      completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "      return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API Error: {e}\")\n",
    "        return \"Story generation failed.\"\n",
    "\n",
    "def chatgpt_generate_red(summary):\n",
    "    \"\"\"Generates a financial story with twists and turns using ChatGPT API.\"\"\"\n",
    "    if not openai.api_key:\n",
    "        print(\"Error: OpenAI API key not found.\")\n",
    "        return \"API Key Missing\"\n",
    "\n",
    "    prompt = (\n",
    "        \"Here is the financial summary: \"\n",
    "        f\"Summary: {summary}\\n\\nRed flags: \"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "      system_message=\"\"\"You are a financial risk analyst tasked with identifying potential red flags in a company’s financial summary. Your goal is to analyze the given financial data, leveraging both the provided summary and any pre-existing knowledge about the company to highlight concerns, risks, or warning signs. Stick to at max 5 points and give it in bullet points\n",
    "\"\"\"\n",
    "      user_prompt=prompt\n",
    "      prompts = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ]\n",
    "      completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "      return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API Error: {e}\")\n",
    "        return \"Story generation failed.\"\n",
    "\n",
    "@app.post(\"/upload/\")\n",
    "async def upload_pdf(file: UploadFile = File(...)):\n",
    "    \"\"\"Handles PDF upload, extracts text, processes it, and returns a summarized result.\"\"\"\n",
    "    pdf_bytes = await file.read()\n",
    "    raw_text = extract_text_from_pdf(pdf_bytes)\n",
    "    extracted_text = extract_sentences_with_numeric_data(raw_text)\n",
    "    summary = summarize_text(extracted_text)\n",
    "    financial_story=chatgpt_generate_story(summary)\n",
    "    green_flags=chatgpt_generate_green(summary)\n",
    "    \n",
    "    red_flags=chatgpt_generate_red(summary)\n",
    "    conclusion=None\n",
    "    visualisations=None\n",
    "    \n",
    "    # Return comprehensive analysis\n",
    "    return {\n",
    "            \"summary\": summary,\n",
    "            \"redFlags\": red_flags,\n",
    "            \"greenFlags\": green_flags,\n",
    "            \"story\": financial_story,\n",
    "            \"conclusion\": conclusion,\n",
    "            \"visualisation\":visualisations\n",
    "        \n",
    "        }\n",
    "\n",
    "\n",
    "class ChatMessage(BaseModel):\n",
    "    message: str\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "\n",
    "# Specific finance-oriented model (small and lightweight)\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Replace with a smaller LLaMA model if needed\n",
    "\n",
    "class FinanceChatbot:\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    async def generate_response(self, query: str) -> str:\n",
    "        if not GROQ_API_KEY:\n",
    "            return \"Sorry, the chatbot is currently unavailable.\"\n",
    "\n",
    "        # Create a structured financial prompt\n",
    "        financial_prompt = f\"Please provide a small chat size response for '{query}' and use normal text not markdown\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gemma2-9b-it\",  \n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful chatbot who get more questions on the financial side but balanced. IF questions asked financial based answer it in terms of company.\"},\n",
    "                          {\"role\": \"user\", \"content\": financial_prompt}],\n",
    "                max_tokens=200,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            return \"I encountered an error processing your query.\"\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "finance_chatbot = FinanceChatbot()\n",
    "\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat_endpoint(chat_message: ChatMessage):\n",
    "    try:\n",
    "        # Generate response using the finance chatbot\n",
    "        response_text = await finance_chatbot.generate_response(chat_message.message)\n",
    "        return {\"response\": response_text}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Run FastAPI inside Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9016936f-c0ab-4f42-be45-2d72b640bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2KThe web browser should have opened for you to authenticate and get an API token.\n",
      "If it didn't, please copy this URL into your web browser manually:\n",
      "\n",
      "\u001b[2K\u001b]8;id=526265;https://modal.com/token-flow/tf-h8NHviRkJxLsLmg9hMfJxo\u001b\\\u001b[4;94mhttps://modal.com/token-flow/tf-h8NHviRkJxLsLmg9hMfJxo\u001b[0m\u001b]8;;\u001b\\\n",
      "\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Waiting for authentication in the web browser\n",
      "\u001b[2K\u001b[32m⠦\u001b[0m Waiting for token flow to complete...\n",
      "\u001b[1A\u001b[2K\u001b[32mWeb authentication finished successfully!\u001b[0m\n",
      "\u001b[32mToken is connected to the \u001b[0m\u001b[35mvishy6400\u001b[0m\u001b[32m workspace.\u001b[0m\n",
      "Verifying token against \u001b[4;34mhttps://api.modal.com\u001b[0m\n",
      "\u001b[32mToken verified successfully!\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Storing token\n",
      "\u001b[1A\u001b[2K\u001b[32mToken written to \u001b[0m\u001b[35m/Users/vishwajithp/\u001b[0m\u001b[35m.modal.toml\u001b[0m\u001b[32m in profile \u001b[0m\u001b[35mvishy6400\u001b[0m\u001b[32m.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9566eeed-5d8f-4c58-914f-3735b05dc04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite inflationary pressures, the company has maintained a strong profit margin. The financial report for the last quarter highlights a steady increase in revenue.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
